# Echo × Bare — Pilot One‑Pager (Draft)

**Purpose**  
Stand up a small, ethical pilot to test whether Echo can 1)engage in meaningful conversations with frontline workers, 2) measurably surface psychosocial risk signals and trigger timely action in Bare’s teams, ans 3) provide near realtime engagement signals to leaders  without eroding trust.

---

## Scope at a glance
- **Participants:** ~25 staff (across roles with meaningful operational load),plus 20 control (BAU) and 1–3 supervisors (dashboard).
- **Arms:**  
  - **Treatment (n≈20):** Weekly 90‑second check‑ins via phone or WhatsApp, supervisor heatmaps.  
  - **Control (n≈20):** Business‑as‑usual. This group completes a survey at the begining and end of the pilot period.  
  - **Robustness test subgroup (n≈5):** Volunteers who intentionally “stress‑test” the system (e.g., inconsistent answers, ignored calls) so we can measure false‑positives and clarity. Participation is consented and never used in performance decisions.
- **Cadence:** 1× 90‑sec check‑in per worker per week; optional micro‑pulse (1–3 items) on alternating weeks.
- **Duration:** ~10–12 weeks total: 2 weeks setup + 1 week dry‑run + 8 weeks live + 1 week close‑out.

---

## What Bare can expect
- **For workers:**  
  - Simple, enaging phone/WhatsApp calls; can opt out or reschedule any time.  
  - Private micro-coaching and signposting; **no raw recordings** to managers.  
- **For supervisors:**  
  - Cohort‑level heatmaps, trends, and a short weekly “what to act on” list.  
  - Named‑by‑exception alerts only for pre‑agreed critical risks (e.g., self‑harm, violence, critical fatigue).  
- **For leadership/board:**  
  - ISO‑45003‑aligned evidence pack with participation, actions taken, and trend movements.

---

## Privacy, ethics, and data
- **Consent‑based** participation; clear, plain‑English info sheet.  
- **Minimal data:** first name, mobile, team, site, manager, roster windows; optional incident/absence feed.  
- **Access:** supervisors see **cohort‑level** patterns; individual details are private except for pre‑agreed exception pathways.  
- **Retention:** pilot data retained for 12 months by default; configurable to Bare’s preference.  
- **Transparency:** periodic “you said, we did” updates to workers.

---

## Success criteria (pilot KPIs)
1. **Coverage:** ≥60% weekly active in Treatment, despite the robustness test subgroup.  
2. **Signal quality:** Clear, actionable flags with controlled false‑positive rate.  
3. **Actioning:** Time‑to‑intervention within SLA; % of actions closed weekly.  
4. **Risk movement:** Directional improvement on relevant psychosocial hazards (e.g., workload, fatigue, exposure to traumatic events, civility/support).  
5. **Trust:** Positive worker sentiment about consent, privacy boundaries, and usefulness.

---

## Timeline and key activities
- **Weeks 0–1 (Setup):**  
  - Sign pilot charter (objectives, KPIs, privacy profile, exception list).  
  - Provide roster/contacts; configure telephony/WhatsApp; finalize agent prompts; supervisor training; worker launch pack.
- **Week 2 (Dry‑run):**  
  - 5–10 internal testers; tune timing/wording/escalations.  
- **Weeks 3–10 (Live, 8 weeks):**  
  - Weekly check‑ins, supervisor actions, mid‑pilot tune.  
  - Weekly KPIs issued to sponsor.  
- **Week 11 (Close‑out):**  
  - Results vs control, lessons learned, board‑ready evidence pack, scale recommendation.

---

## What we need from Bare (before kickoff)
- Named **executive sponsor** and **pilot manager**.  
- List of ~30 participants with team/manager/roster info; confirm robustness subgroup volunteers.  
- **Escalation contacts:** EAP and WHS on‑call.  
- Sign‑off on privacy profile and the named‑by‑exception list.

---

## Deliverables
- Weekly pilot KPI note and “you said, we did” highlights.  
- Mid‑pilot tuning memo (if needed).  
- Final report with control vs treatment deltas and ISO‑45003‑aligned evidence pack.

---

**Contact:**  
Fletcher Young, Echo — Founder & CPO  
hello@echo-control.com | +61 (0) ————

